#ranks<-10 ;
#uranks<-10 ;
n<-dim(X)[1] ; p<-dim(X)[2]
iXX<-solve(t(X)%*%X)  ; V<-iXX*(n/(n+1)) ; cholV<-chol(V)
#### Ordinal probit regression
## setup
set.seed(1)
beta<-rep(0,p)
z<-qnorm(rank(y,ties.method="random")/(n+1))
g<-rep(NA,length(uranks)-1)
K<-length(uranks)
BETA<-matrix(NA,1000,p) ; Z<-matrix(NA,1000,n) ; ac<-0
mu<-rep(0,K-1) ; sigma<-rep(1000,K-1)
## MCMC
S<-25000
for(s in 1:S)
{
#update g
for(k in 1:(K-1))
{
a<-max(z[y==k])
b<-min(z[y==k+1])
u<-runif(1, pnorm( (a-mu[k])/sigma[k] ),
pnorm( (b-mu[k])/sigma[k] ) )
g[k]<- mu[k] + sigma[k]*qnorm(u)
}
#update beta
E<- V%*%( t(X)%*%z )
beta<- cholV%*%rnorm(p) + E
#update z
ez<-X%*%beta
a<-c(-Inf,g)[ match( y-1, 0:K) ]
b<-c(g,Inf)[y]
u<-runif(n, pnorm(a-ez),pnorm(b-ez) )
z<- ez + qnorm(u)
#help mixing
c<-rnorm(1,0,n^(-1/3))
zp<-z+c ; gp<-g+c
lhr<-  sum(dnorm(zp,ez,1,log=T) - dnorm(z,ez,1,log=T) ) +
sum(dnorm(gp,mu,sigma,log=T) - dnorm(g,mu,sigma,log=T) )
if(log(runif(1))<lhr) { z<-zp ; g<-gp ; ac<-ac+1 }
if(s%%(S/1000)==0)
{
#cat(s/S,ac/s,"\n")
BETA[s/(S/1000),]<-  beta
Z[s/(S/1000),]<- z
}
}
# Assuming BETA and Z matrices are available from the MCMC sampling
# Extract mean values from MCMC samples
mean_beta <- colMeans(BETA, na.rm = TRUE)
# Extract relevant columns from the test set
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
# Make predictions using the mean of MCMC samples
final_g <- X_test %*% mean_beta
# Convert predictions to ordinal labels
predicted_labels <- cut(final_g,
breaks = c(-Inf, g, Inf),
labels = c(1, 2, 3, 4, 5, 6),
include.lowest = TRUE)
# Evaluate the predictions (assuming you have true ordinal_quality values for the test set)
confusion_matrix <- table(predicted_labels, test_data$quality)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Print the confusion matrix and accuracy
print("Confusion Matrix:")
print(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
View(data)
View(test_data)
View(test_data)
View(train_data)
View(test_data)
### QUALITY, NOT ORDINAL_QUALITY
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality-2
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
yquality<-match(train_data$quality,sort(unique(train_data$quality)))
# Regress on all
tmp<-lm(yquality ~ ., data=train_data)
#####
X<-as.matrix(train_data[, !grepl("quality", names(train_data))]) # drop Y column
y<-train_data$quality
keep<- (1:length(y))[ !is.na( apply( cbind(X,y),1,mean) ) ]
X<-X[keep,] ; y<-y[keep]
ranks<-match(y,sort(unique(y))) ;
uranks<-sort(unique(ranks))
#ranks<-10 ;
#uranks<-10 ;
n<-dim(X)[1] ; p<-dim(X)[2]
iXX<-solve(t(X)%*%X)  ; V<-iXX*(n/(n+1)) ; cholV<-chol(V)
#### Ordinal probit regression
## setup
set.seed(1)
beta<-rep(0,p)
z<-qnorm(rank(y,ties.method="random")/(n+1))
g<-rep(NA,length(uranks)-1)
K<-length(uranks)
BETA<-matrix(NA,1000,p) ; Z<-matrix(NA,1000,n) ; ac<-0
mu<-rep(0,K-1) ; sigma<-rep(1000,K-1)
## MCMC
S<-25000
for(s in 1:S)
{
#update g
for(k in 1:(K-1))
{
a<-max(z[y==k])
b<-min(z[y==k+1])
u<-runif(1, pnorm( (a-mu[k])/sigma[k] ),
pnorm( (b-mu[k])/sigma[k] ) )
g[k]<- mu[k] + sigma[k]*qnorm(u)
}
#update beta
E<- V%*%( t(X)%*%z )
beta<- cholV%*%rnorm(p) + E
#update z
ez<-X%*%beta
a<-c(-Inf,g)[ match( y-1, 0:K) ]
b<-c(g,Inf)[y]
u<-runif(n, pnorm(a-ez),pnorm(b-ez) )
z<- ez + qnorm(u)
#help mixing
c<-rnorm(1,0,n^(-1/3))
zp<-z+c ; gp<-g+c
lhr<-  sum(dnorm(zp,ez,1,log=T) - dnorm(z,ez,1,log=T) ) +
sum(dnorm(gp,mu,sigma,log=T) - dnorm(g,mu,sigma,log=T) )
if(log(runif(1))<lhr) { z<-zp ; g<-gp ; ac<-ac+1 }
if(s%%(S/1000)==0)
{
#cat(s/S,ac/s,"\n")
BETA[s/(S/1000),]<-  beta
Z[s/(S/1000),]<- z
}
}
# Assuming BETA and Z matrices are available from the MCMC sampling
# Extract mean values from MCMC samples
mean_beta <- colMeans(BETA, na.rm = TRUE)
# Extract relevant columns from the test set
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
# Make predictions using the mean of MCMC samples
final_g <- X_test %*% mean_beta
# Convert predictions to ordinal labels
predicted_labels <- cut(final_g,
breaks = c(-Inf, g, Inf),
labels = c(3, 4, 5, 6, 7, 8),
include.lowest = TRUE)
# Evaluate the predictions (assuming you have true ordinal_quality values for the test set)
confusion_matrix <- table(predicted_labels, test_data$quality+2)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Print the confusion matrix and accuracy
print("Confusion Matrix:")
print(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
knitr::opts_chunk$set(echo = TRUE)
library("latex2exp")
library("ggplot2")
library("MASS")
#library("MCMCpack")
library("coda")
library("dplyr")
library("tidyr")
library("caret")
library("reshape2")
library("DescTools")
# Exploratory Data Analysis
getwd()
rm(list = ls())
#try standardizing the data and seeing if that helps
#try splitting the categories into good vs bad
# Read your CSV data
data <- read.csv("winequality-red.csv", sep=';')
# Extract the "quality" column
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
standardized_data$ordinal_quality <- cut(standardized_data$quality,
breaks = c(-Inf, 4.5, 5.5, Inf),
labels = c(1, 2, 3),
include.lowest = TRUE)
# If you want to convert the new_column to numeric type
standardized_data$ordinal_quality <- as.numeric(standardized_data$ordinal_quality)
# Summary statistics
summary_stats <- summary(standardized_data)
# Features
features <- c("fixed.acidity", "volatile.acidity", "citric.acid",
"residual.sugar", "chlorides", "free.sulfur.dioxide",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
all_features <- c("fixed.acidity", "volatile.acidity", "citric.acid",
"residual.sugar", "chlorides", "free.sulfur.dioxide",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol", "quality")
# Pairwise scatterplots
pairwise_scatterplots <- pairs(standardized_data[, all_features])
# Assuming your data frame is named "data"
correlation_matrix <- cor(standardized_data[, all_features])
# Convert the correlation matrix to a long format
correlation_long <- melt(correlation_matrix)
# Create a heatmap using ggplot2
heatmap <- ggplot(data = correlation_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
theme_minimal() +
labs(title = "Correlation Heatmap", x = "", y = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Histograms for continuous variables
histograms <- lapply(features, function(var) {
ggplot(standardized_data, aes(x = get(var))) +
geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(title = paste("Histogram of", var), x = var, y = "Frequency") +
theme_minimal()
})
histograms_quality <- ggplot(standardized_data, aes(x = data$quality)) +
geom_histogram(bins=10, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Quality", x = "Quality", y = "Frequency") +
theme_minimal()
# Boxplots - Separated out sulfur since scales much larger
# Extracting the variables for separate box plots
sulfur_variables <- c("total.sulfur.dioxide", "free.sulfur.dioxide")
other_variables <- setdiff(all_features, sulfur_variables)
# Boxplot for sulfur variables
boxplot_sulfur <- ggplot(data %>% pivot_longer(cols = sulfur_variables),
aes(x = name, y = value)) +
geom_boxplot(fill = "blue", color = "black", alpha = 0.7, width = 0.5) +
labs(title = "Boxplots of Sulfur Variables", x = "Variable", y = "Value") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_y_continuous(expand = expansion(mult = c(0.05, 0.2)))
# Boxplot for other variables
boxplot_other <- ggplot(data %>% pivot_longer(cols = other_variables),
aes(x = name, y = value)) +
geom_boxplot(fill = "blue", color = "black", alpha = 0.7, width = 0.5) +
labs(title = "Boxplots of Other Variables", x = "Variable", y = "Value") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_y_continuous(expand = expansion(mult = c(0.05, 0.2)))
# Quantiles, means, medians, and standard deviations
quantiles_means_medians_sds <- standardized_data %>%
summarise(across(features, list(quantiles = ~quantile(.),
mean = ~mean(.),
median = ~median(.),
sd = ~sd(.),
min = ~min(.),
max = ~max(.))))
# Print summary statistics
print(summary_stats)
# Display pairwise scatterplots
print(pairwise_scatterplots)
# Display Heatmap
print(heatmap)
# Display histograms
for (hist_plot in histograms) {
print(hist_plot)
}
print(histograms_quality)
# Display boxplot
print(boxplot_sulfur)
print(boxplot_other)
# Display quantiles, means, medians, and standard deviations
print(quantiles_means_medians_sds)
#Plot the probability distribution for quality ratings
# Calculate probabilities of each ranking
rank_probs <- prop.table(table(standardized_data$quality))
# Create a dataframe for probabilities
plot_data <- data.frame(Rank = as.numeric(names(rank_probs)), Probability = as.vector(rank_probs))
# Create the ggplot
ggplot(plot_data, aes(x = Rank, y = Probability)) +
geom_bar(stat = "identity", fill = "blue", color = "black", alpha = 0.7, width = 0.5) +
labs(title = "Probability Distribution of Quality Ratings",
x = "Quality Rating",
y = "Probability") +
theme_minimal()
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(quality ~ ., data = train_data, method = "logistic")
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(factor(quality) ~ ., data = train_data, method = "logistic")
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
# Display the final model
summary(final_model)
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(factor(quality) ~ ., data = train_data, method = "logistic")
# Perform backward elimination using stepwise regression
#final_model <- step(initial_model, direction = "backward")
final_model_p <- step(initial_model, direction = "backward", criterion = "p-value")
# Display the final model
summary(final_model)
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(factor(quality) ~ ., data = train_data, method = "logistic")
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
#final_model_p <- step(initial_model, direction = "backward", criterion = "p-value")
# Display the final model
summary(final_model)
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
predicted_labels <- predict(final_model, newdata = X_test)
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(factor(quality) ~ ., data = train_data, method = "logistic")
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
#final_model_p <- step(initial_model, direction = "backward", criterion = "p-value")
# Display the final model
summary(final_model)
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
predicted_labels <- predict(final_model, newdata = X_test)
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
print(accuracy)
knitr::opts_chunk$set(echo = TRUE)
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
library("latex2exp")
library("ggplot2")
library("MASS")
#library("MCMCpack")
library("coda")
library("dplyr")
library("tidyr")
library("caret")
library("reshape2")
library("DescTools")
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(factor(quality) ~ ., data = train_data, method = "logistic")
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
final_model <- step(initial_model, direction = "backward", criterion = "p-value")
# Display the final model
summary(final_model)
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
predicted_labels <- predict(final_model, newdata = X_test)
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
print(accuracy)
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
features_reg <- c("fixed.acidity",
"residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
# take out variables with high correlation
all_features <- setdiff(features, "quality")
#selected_features <- all_features
selected_features <- c(all_features, "fixed.acidity*density", "alcohol*density")
initial_model <- polr(factor(quality) ~ ., data = train_data, method = "logistic")
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
final_model <- step(initial_model, direction = "backward", criterion = "p-value")
# Display the final model
summary(final_model)
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
predicted_labels <- predict(final_model, newdata = X_test)
predicted_labels <- as.integer(predicted_labels)
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
print(accuracy)
