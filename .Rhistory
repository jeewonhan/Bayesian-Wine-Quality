accuracy_baseline <- sum(predicted_labels_baseline == true_labels) / length(true_labels)
cat("Accuracy for the baseline model:", accuracy_baseline, "\n")
# Ordinal Regression
# Backward elimination for the most parsimonious model
# Non-correlated features
features_reg <- c("residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
all_features <- setdiff(features_reg, "quality")
# Interaction Terms
selected_features <- c(all_features, "residual.sugar*chlorides", "residual.sugar*total.sulfur.dioxide",
"residual.sugar*density", "residual.sugar*pH", "residual.sugar*sulphates",
"residual.sugar*alcohol", "chlorides*total.sulfur.dioxide",
"chlorides*density", "chlorides*pH", "chlorides*sulphates", "chlorides*alcohol",
"total.sulfur.dioxide*density", "total.sulfur.dioxide*pH",
"total.sulfur.dioxide*sulphates", "total.sulfur.dioxide*alcohol",
"density*pH", "density*sulphates", "density*alcohol", "pH*sulphates",
"pH*alcohol", "sulphates*alcohol")
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
formula_str <- paste("factor(quality) ~ ", paste(current_features, collapse = "+"), sep = "")
model <- polr(as.formula(formula_str), data = train_data, Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
#cat("Selected features:", selected_features, "\n")
#cat("Current accuracy:", current_accuracy, "\n")
#cat("Current number of variables:", current_num_variables, "\n\n")
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
# Multiple Regression
initial_model <- lm(quality ~ residual.sugar + chlorides + total.sulfur.dioxide + density+ pH +
sulphates + alcohol + residual.sugar*chlorides +
residual.sugar*total.sulfur.dioxide +
residual.sugar*density + residual.sugar*pH + residual.sugar*sulphates +
residual.sugar*alcohol + chlorides*total.sulfur.dioxide +
chlorides*density + chlorides*pH + chlorides*sulphates + chlorides*alcohol +
total.sulfur.dioxide*density + total.sulfur.dioxide*pH +
total.sulfur.dioxide*sulphates + total.sulfur.dioxide*alcohol +
density*pH + density*sulphates + density*alcohol + pH*sulphates +
pH*alcohol + sulphates*alcohol, data = train_data)
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
# Display the final model
summary(final_model)
X_test <- as.data.frame(test_data[, !grepl("quality", names(test_data))])
predicted_labels <- predict(final_model, newdata = X_test)
predicted_labels <- as.integer(predicted_labels)
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
print(accuracy)
### 1-3 Target Variable
# Standardize Data
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
standardized_data <- cbind(quality = quality_column, standardized_data)
standardized_data$ordinal_quality <- cut(standardized_data$quality,
breaks = c(-Inf, 4.5, 5.5, Inf),
labels = c(1, 2, 3),
include.lowest = TRUE)
standardized_data$ordinal_quality <- as.numeric(standardized_data$ordinal_quality)
standardized_data <- select(standardized_data, -quality)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$ordinal_quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
# Baseline Model
most_common_quality <- Mode(train_data$ordinal_quality)
baseline_prediction <- rep(most_common_quality, nrow(test_data))
predicted_labels_baseline <- as.integer(baseline_prediction)
true_labels <- as.integer(test_data$ordinal_quality)
# Accuracy
accuracy_baseline <- sum(predicted_labels_baseline == true_labels) / length(true_labels)
cat("Accuracy for the baseline model:", accuracy_baseline, "\n")
# Ordinal Regression
# Backward elimination for the most parsimonious model
# Non-correlated features
features_reg <- c("residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol")
all_features <- setdiff(features_reg, "ordinal_quality")
# Interaction Terms
selected_features <- c(all_features, "residual.sugar*chlorides", "residual.sugar*total.sulfur.dioxide",
"residual.sugar*density", "residual.sugar*pH", "residual.sugar*sulphates",
"residual.sugar*alcohol", "chlorides*total.sulfur.dioxide",
"chlorides*density", "chlorides*pH", "chlorides*sulphates", "chlorides*alcohol",
"total.sulfur.dioxide*density", "total.sulfur.dioxide*pH",
"total.sulfur.dioxide*sulphates", "total.sulfur.dioxide*alcohol",
"density*pH", "density*sulphates", "density*alcohol", "pH*sulphates",
"pH*alcohol", "sulphates*alcohol")
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
formula_str <- paste("factor(ordinal_quality) ~ ", paste(current_features, collapse = "+"), sep = "")
model <- polr(as.formula(formula_str), data = train_data, Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$ordinal_quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
#cat("Selected features:", selected_features, "\n")
#cat("Current accuracy:", current_accuracy, "\n")
#cat("Current number of variables:", current_num_variables, "\n\n")
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
# Multiple Regression
initial_model <- lm(ordinal_quality ~ residual.sugar + chlorides + total.sulfur.dioxide +
density+ pH + sulphates + alcohol + residual.sugar*chlorides +
residual.sugar*total.sulfur.dioxide +
residual.sugar*density + residual.sugar*pH + residual.sugar*sulphates +
residual.sugar*alcohol + chlorides*total.sulfur.dioxide +
chlorides*density + chlorides*pH + chlorides*sulphates + chlorides*alcohol +
total.sulfur.dioxide*density + total.sulfur.dioxide*pH +
total.sulfur.dioxide*sulphates + total.sulfur.dioxide*alcohol +
density*pH + density*sulphates + density*alcohol + pH*sulphates +
pH*alcohol + sulphates*alcohol, data = train_data)
# Perform backward elimination using stepwise regression
final_model <- step(initial_model, direction = "backward")
# Display the final model
summary(final_model)
X_test <- as.data.frame(test_data[, !grepl("ordinal_quality", names(test_data))])
predicted_labels <- predict(final_model, newdata = X_test)
predicted_labels <- as.integer(predicted_labels)
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$ordinal_quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
print(accuracy)
library("latex2exp")
library("ggplot2")
library("MASS")
library("coda")
library("dplyr")
library("tidyr")
library("caret")
library("reshape2")
library("DescTools")
rm(list=ls())
#Preprocessing to prepare the data for Bayesian regression on Quality
#Read data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
standardized_data <- cbind(quality = quality_column, standardized_data)
set.seed(123)  # Set seed for reproducibility
# Interaction Terms
interaction_terms <- c("residual.sugar*chlorides", "residual.sugar*total.sulfur.dioxide",
"residual.sugar*density", "residual.sugar*pH", "residual.sugar*sulphates",
"residual.sugar*alcohol", "chlorides*total.sulfur.dioxide",
"chlorides*density", "chlorides*pH", "chlorides*sulphates", "chlorides*alcohol",
"total.sulfur.dioxide*density", "total.sulfur.dioxide*pH",
"total.sulfur.dioxide*sulphates", "total.sulfur.dioxide*alcohol",
"density*pH", "density*sulphates", "density*alcohol", "pH*sulphates",
"pH*alcohol", "sulphates*alcohol")
# Iterate through the interaction terms and create new columns for each interaction term
for (term in interaction_terms) {
terms <- strsplit(term, "\\*")[[1]]
col_name <- paste(terms, collapse = "_times_")
# Create the new column
standardized_data <- mutate(standardized_data, !!col_name := !!sym(terms[1]) * !!sym(terms[2]))
}
# Non-correlated features
features_reg <- c("residual.sugar", "chlorides",
"total.sulfur.dioxide", "density", "pH", "sulphates",
"alcohol",
"residual.sugar_times_chlorides",
"residual.sugar_times_total.sulfur.dioxide",
"residual.sugar_times_density",
"residual.sugar_times_pH",
"residual.sugar_times_sulphates",
"residual.sugar_times_alcohol",
"chlorides_times_total.sulfur.dioxide",
"chlorides_times_density",
"chlorides_times_pH",
"chlorides_times_sulphates",
"chlorides_times_alcohol",
"total.sulfur.dioxide_times_density",
"total.sulfur.dioxide_times_pH",
"total.sulfur.dioxide_times_sulphates",
"total.sulfur.dioxide_times_alcohol",
"density_times_pH",
"density_times_sulphates",
"density_times_alcohol",
"pH_times_sulphates",
"pH_times_alcohol",
"sulphates_times_alcohol",
"quality")
standardized_data <- standardized_data[, (names(standardized_data) %in% features_reg)]
standardized_data_q <- standardized_data
### ordered probit regression with ordinal_quality as the target variable
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(oq_model$ordinal_quality, p = 0.8, list = FALSE)
library("latex2exp")
library("ggplot2")
library("MASS")
#library("MCMCpack")
library("coda")
library("dplyr")
library("tidyr")
library("caret")
library("reshape2")
library("DescTools")
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Add ordinal_quality - don't do when doing quality
standardized_data$ordinal_quality <- cut(standardized_data$quality,
breaks = c(-Inf, 4.5, 5.5, Inf),
labels = c(1, 2, 3),
include.lowest = TRUE)
# Convert the new_column to numeric type
standardized_data$ordinal_quality <- as.numeric(standardized_data$ordinal_quality)
# DROP QUALITY COLUMN - when doing ordinal quality
standardized_data <- standardized_data[, !(names(standardized_data) %in% c("quality"))]
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$ordinal_quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
yordquality<-match(train_data$ordinal_quality,sort(unique(train_data$ordinal_quality)))
# Regress on all
tmp<-lm(yordquality ~ ., data=train_data)
#####
X<-as.matrix(train_data[, !grepl("ordinal_quality", names(train_data))]) # drop Y column
y<-train_data$ordinal_quality
keep<- (1:length(y))[ !is.na( apply( cbind(X,y),1,mean) ) ]
X<-X[keep,] ; y<-y[keep]
ranks<-match(y,sort(unique(y))) ; uranks<-sort(unique(ranks))
n<-dim(X)[1] ; p<-dim(X)[2]
iXX<-solve(t(X)%*%X)  ; V<-iXX*(n/(n+1)) ; cholV<-chol(V)
#### Ordinal probit regression
## setup
set.seed(1)
beta<-rep(0,p)
z<-qnorm(rank(y,ties.method="random")/(n+1))
g<-rep(NA,length(uranks)-1)
K<-length(uranks)
BETA<-matrix(NA,1000,p) ; Z<-matrix(NA,1000,n) ; ac<-0
mu<-rep(0,K-1) ; sigma<-rep(1000,K-1)
## MCMC
S<-25000
for(s in 1:S)
{
#update g
for(k in 1:(K-1))
{
a<-max(z[y==k])
b<-min(z[y==k+1])
u<-runif(1, pnorm( (a-mu[k])/sigma[k] ),
pnorm( (b-mu[k])/sigma[k] ) )
g[k]<- mu[k] + sigma[k]*qnorm(u)
}
#update beta
E<- V%*%( t(X)%*%z )
beta<- cholV%*%rnorm(p) + E
#update z
ez<-X%*%beta
a<-c(-Inf,g)[ match( y-1, 0:K) ]
b<-c(g,Inf)[y]
u<-runif(n, pnorm(a-ez),pnorm(b-ez) )
z<- ez + qnorm(u)
#help mixing
c<-rnorm(1,0,n^(-1/3))
zp<-z+c ; gp<-g+c
lhr<-  sum(dnorm(zp,ez,1,log=T) - dnorm(z,ez,1,log=T) ) +
sum(dnorm(gp,mu,sigma,log=T) - dnorm(g,mu,sigma,log=T) )
if(log(runif(1))<lhr) { z<-zp ; g<-gp ; ac<-ac+1 }
if(s%%(S/1000)==0)
{
#cat(s/S,ac/s,"\n")
BETA[s/(S/1000),]<-  beta
Z[s/(S/1000),]<- z
}
}
# Assuming BETA and Z matrices are available from the MCMC sampling
# Extract mean values from MCMC samples
mean_beta <- colMeans(BETA, na.rm = TRUE)
# Extract relevant columns from the test set
X_test <- as.matrix(test_data[, !grepl("ordinal_quality", names(test_data))])
# Make predictions using the mean of MCMC samples
final_g <- X_test %*% mean_beta
predicted_labels <- cut(final_g,
breaks = c(-Inf, g, Inf),
labels = c(1, 2, 3),
include.lowest = TRUE)
# Convert predictions to ordinal labels
# predicted_labels <- cut(final_predictions,
#                         breaks = c(-Inf, 1.5, 2.5, Inf),
#                         labels = c(1, 2, 3),
#                         include.lowest = TRUE)
# Evaluate the predictions (assuming you have true ordinal_quality values for the test set)
confusion_matrix <- table(predicted_labels, test_data$ordinal_quality)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Print the confusion matrix and accuracy
print("Confusion Matrix:")
print(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
### QUALITY, NOT ORDINAL_QUALITY
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality-2
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
yquality<-match(train_data$quality,sort(unique(train_data$quality)))
# Regress on all
tmp<-lm(yquality ~ ., data=train_data)
#####
X<-as.matrix(train_data[, !grepl("quality", names(train_data))]) # drop Y column
y<-train_data$quality
keep<- (1:length(y))[ !is.na( apply( cbind(X,y),1,mean) ) ]
X<-X[keep,] ; y<-y[keep]
ranks<-match(y,sort(unique(y))) ;
uranks<-sort(unique(ranks))
#ranks<-10 ;
#uranks<-10 ;
n<-dim(X)[1] ; p<-dim(X)[2]
iXX<-solve(t(X)%*%X)  ; V<-iXX*(n/(n+1)) ; cholV<-chol(V)
#### Ordinal probit regression
## setup
set.seed(1)
beta<-rep(0,p)
z<-qnorm(rank(y,ties.method="random")/(n+1))
g<-rep(NA,length(uranks)-1)
K<-length(uranks)
BETA<-matrix(NA,1000,p) ; Z<-matrix(NA,1000,n) ; ac<-0
mu<-rep(0,K-1) ; sigma<-rep(1000,K-1)
## MCMC
S<-25000
for(s in 1:S)
{
#update g
for(k in 1:(K-1))
{
a<-max(z[y==k])
b<-min(z[y==k+1])
u<-runif(1, pnorm( (a-mu[k])/sigma[k] ),
pnorm( (b-mu[k])/sigma[k] ) )
g[k]<- mu[k] + sigma[k]*qnorm(u)
}
#update beta
E<- V%*%( t(X)%*%z )
beta<- cholV%*%rnorm(p) + E
#update z
ez<-X%*%beta
a<-c(-Inf,g)[ match( y-1, 0:K) ]
b<-c(g,Inf)[y]
u<-runif(n, pnorm(a-ez),pnorm(b-ez) )
z<- ez + qnorm(u)
#help mixing
c<-rnorm(1,0,n^(-1/3))
zp<-z+c ; gp<-g+c
lhr<-  sum(dnorm(zp,ez,1,log=T) - dnorm(z,ez,1,log=T) ) +
sum(dnorm(gp,mu,sigma,log=T) - dnorm(g,mu,sigma,log=T) )
if(log(runif(1))<lhr) { z<-zp ; g<-gp ; ac<-ac+1 }
if(s%%(S/1000)==0)
{
#cat(s/S,ac/s,"\n")
BETA[s/(S/1000),]<-  beta
Z[s/(S/1000),]<- z
}
}
# Assuming BETA and Z matrices are available from the MCMC sampling
# Extract mean values from MCMC samples
mean_beta <- colMeans(BETA, na.rm = TRUE)
# Extract relevant columns from the test set
X_test <- as.matrix(test_data[, !grepl("quality", names(test_data))])
# Make predictions using the mean of MCMC samples
final_g <- X_test %*% mean_beta
# Convert predictions to ordinal labels
predicted_labels <- cut(final_g,
breaks = c(-Inf, g, Inf),
labels = c(3, 4, 5, 6, 7, 8),
include.lowest = TRUE)
# Evaluate the predictions (assuming you have true ordinal_quality values for the test set)
confusion_matrix <- table(predicted_labels, test_data$quality+2)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Print the confusion matrix and accuracy
print("Confusion Matrix:")
print(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Data
data <- read.csv("winequality-red.csv", sep=';')
quality_column <- data$quality
# Standardize all columns except the "quality" column
standardized_data <- as.data.frame(scale(data[, -which(names(data) == "quality")]))
# Add the "quality" column back to the standardized dataframe
standardized_data <- cbind(quality = quality_column, standardized_data)
# Add ordinal_quality - don't do when doing quality
standardized_data$ordinal_quality <- cut(standardized_data$quality,
breaks = c(-Inf, 4.5, 5.5, Inf),
labels = c(1, 2, 3),
include.lowest = TRUE)
# Convert the new_column to numeric type
standardized_data$ordinal_quality <- as.numeric(standardized_data$ordinal_quality)
# DROP QUALITY COLUMN - when doing ordinal quality
standardized_data <- standardized_data[, !(names(standardized_data) %in% c("quality"))]
# Train/Test Split
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(standardized_data$ordinal_quality, p = 0.8, list = FALSE)
train_data <- standardized_data[split_index, ]
test_data <- standardized_data[-split_index, ]
yordquality<-match(train_data$ordinal_quality,sort(unique(train_data$ordinal_quality)))
# Regress on all
tmp<-lm(yordquality ~ ., data=train_data)
#####
X<-as.matrix(train_data[, !grepl("ordinal_quality", names(train_data))]) # drop Y column
y<-train_data$ordinal_quality
keep<- (1:length(y))[ !is.na( apply( cbind(X,y),1,mean) ) ]
X<-X[keep,] ; y<-y[keep]
ranks<-match(y,sort(unique(y))) ; uranks<-sort(unique(ranks))
n<-dim(X)[1] ; p<-dim(X)[2]
iXX<-solve(t(X)%*%X)  ; V<-iXX*(n/(n+1)) ; cholV<-chol(V)
## setup
set.seed(1)
beta<-rep(0,p)
z<-qnorm(rank(y,ties.method="random")/(n+1))
g<-rep(NA,length(uranks)-1)
K<-length(uranks)
BETA<-matrix(NA,1000,p) ; Z<-matrix(NA,1000,n) ; ac<-0
mu<-rep(0,K-1) ; sigma<-rep(1000,K-1)
