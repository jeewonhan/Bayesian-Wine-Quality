cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) > 0) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
next  # Skip fitting when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) > 0) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
break  # Skip fitting when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
# Remove the worst feature from the selected features
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
selected_features <- setdiff(selected_features, worst_feature)
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
# Frequentist Ordinal Regression
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(all_features) > 1) {
accuracies <- numeric(length(all_features))
for (i in seq_along(all_features)) {
current_features <- setdiff(all_features, all_features[i])
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Compute accuracy
accuracies[i] <- sum(as.integer(predicted_labels) == as.integer(test_data$quality)) / nrow(test_data)
}
best_feature_index <- which.max(accuracies)
best_accuracy <- accuracies[best_feature_index]
best_feature <- all_features[best_feature_index]
best_num_variables <- length(all_features)
if (length(all_features) == 2) {
break  # Exit the loop when only one feature is left
}
# Remove the best feature from the list of all features
all_features <- setdiff(all_features, best_feature)
cat("Best feature set:", all_features, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n\n")
}
# Frequentist Ordinal Regression
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(all_features) > 1) {
accuracies <- numeric(length(all_features))
for (i in seq_along(all_features)) {
current_features <- setdiff(all_features, all_features[i])
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Compute accuracy
accuracies[i] <- sum(as.integer(predicted_labels) == as.integer(test_data$quality)) / nrow(test_data)
}
best_feature_index <- which.max(accuracies)
best_accuracy <- accuracies[best_feature_index]
best_feature <- all_features[best_feature_index]
best_num_variables <- length(all_features)
if (length(all_features) == 0) {
break  # Exit the loop when only one feature is left
}
# Remove the best feature from the list of all features
all_features <- setdiff(all_features, best_feature)
cat("Best feature set:", all_features, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n\n")
}
# Frequentist Ordinal Regression
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(all_features) > 1) {
accuracies <- numeric(length(all_features))
for (i in seq_along(all_features)) {
current_features <- setdiff(all_features, all_features[i])
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Compute accuracy
accuracies[i] <- sum(as.integer(predicted_labels) == as.integer(test_data$quality)) / nrow(test_data)
}
best_feature_index <- which.max(accuracies)
best_accuracy <- accuracies[best_feature_index]
best_feature <- all_features[best_feature_index + 1]  # Adjust index to get the correct feature
best_num_variables <- length(all_features)
if (length(all_features) == 2) {
break  # Exit the loop when only one feature is left
}
# Remove the best feature from the list of all features
all_features <- setdiff(all_features, best_feature)
cat("Best feature set:", all_features, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n\n")
}
# Frequentist Ordinal Regression
# Assuming you have a data frame named "data" containing your features and labels
set.seed(123)  # Set seed for reproducibility
split_index <- createDataPartition(data$quality, p = 0.8, list = FALSE)
# Train/Test Split
train_data <- data[split_index, ]
test_data <- data[-split_index, ]
# Backward elimination for the most parsimonious model
all_features <- setdiff(names(train_data), "quality")
selected_features <- all_features
best_accuracy <- 0
best_feature_set <- NULL
best_num_variables <- Inf  # Initialize with a large value
while (length(selected_features) >= 1) {
current_accuracy <- 0
current_num_variables <- length(selected_features)
worst_feature <- NULL
exit_loop <- FALSE  # Flag to control loop exit
for (feature in selected_features) {
current_features <- setdiff(selected_features, feature)
if (length(current_features) == 0) {
exit_loop <- TRUE
break  # Exit the inner loop when only one feature is left
}
# Train the model with the current set of features
model <- polr(factor(quality) ~ ., data = train_data[, c("quality", current_features)], Hess = TRUE)
# Predict using the trained model on the test set
# (Ensure test_data is also a data frame)
predicted_labels <- predict(model, newdata = as.data.frame(test_data))
# Convert predicted and true labels to integers (if not already)
predicted_labels <- as.integer(predicted_labels)
true_labels <- as.integer(test_data$quality)
# Compute accuracy
accuracy <- sum(predicted_labels == true_labels) / length(true_labels)
# Update the current accuracy, worst feature, and number of variables if needed
if (accuracy > current_accuracy) {
current_accuracy <- accuracy
worst_feature <- feature
current_num_variables <- length(current_features)
}
}
if (exit_loop) {
break  # Exit the outer loop when only one feature is left
}
# Remove the worst feature from the selected features
selected_features <- setdiff(selected_features, worst_feature)
# Update the best feature set, accuracy, and number of variables if needed
if (current_accuracy > best_accuracy ||
(current_accuracy == best_accuracy && current_num_variables < best_num_variables)) {
best_accuracy <- current_accuracy
best_feature_set <- selected_features
best_num_variables <- current_num_variables
}
cat("Selected features:", selected_features, "\n")
cat("Current accuracy:", current_accuracy, "\n")
cat("Current number of variables:", current_num_variables, "\n\n")
}
cat("Best feature set:", best_feature_set, "\n")
cat("Best accuracy:", best_accuracy, "\n")
cat("Best number of variables:", best_num_variables, "\n")
